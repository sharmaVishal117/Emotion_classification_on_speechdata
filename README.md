# MARS Open Projects 2025 - Project 1: Speech Emotion Recognition System
ğŸ¯ Project Overview
This project implements a sophisticated Speech Emotion Recognition (SER) system using deep learning techniques as part of the MARS Open Projects 2025 initiative. The system employs a hybrid CNN + SE blocks architecture trained on the RAVDESS dataset to classify emotions in speech and song audio files with high accuracy.

ğŸ“‹ Project Requirements
-Primary Objective: Develop an AI system that can accurately identify emotions from speech audio
-Performance Targets:
-Weighted F1 Score > 80%
-Overall Accuracy > 80%
-Individual Class Recalls > 75%
-Dataset: RAVDESS (Ryerson Audio-Visual Database of Emotional Speech and Song)
-Implementation: Complete end-to-end pipeline with web interface

ğŸµ Emotion Classification Categories
The system recognizes 8 distinct emotional states:

Emotion	   Code	          Description	Icon
Neutral	    01	        Baseline emotional state	ğŸ˜
Calm	    02	        Peaceful, relaxed state	ğŸ˜Œ
Happy	    03         	Joyful, positive state	ğŸ˜„
Sad	        04	        Sorrowful, melancholic state	ğŸ˜¢
Angry	    05	        Aggressive, frustrated state	ğŸ˜ 
Fearful	    06	        Scared, anxious state	ğŸ˜¨
Disgust	    07	        Repulsed, disgusted state	ğŸ¤¢

ğŸ— System Architecture

ğŸ—ï¸ Layers:
-Stacked Conv1D layers with:
-BatchNormalization
-MaxPooling1D
-Dropout

âœ… SE Blocks (Squeeze-and-Excitation for channel attention)
-GlobalAveragePooling1D for spatial feature aggregation
-Dense layers with ReLU activation
-Final Dense layer with Softmax for multi-class classification

ğŸ§ Feature Engineering
-Audio Processing: 3-second segments at 22.05kHz sampling rate
-Feature Extraction: 60 MFCCs Ã— 130 time steps per audio
-Data Augmentation:
-Gaussian noise
-Time shifting
-Spectral masking
-Normalization: StandardScaler applied to flattened MFCC features

âš™ï¸ Loss Function & Optimization
-Loss: Categorical Focal Loss (gamma=2.0) to address class imbalance
-Optimizer: Adam (learning_rate=1e-4)
-Callbacks:
-EarlyStopping(patience=10, restore_best_weights=True)
-Regularization:
-Dropout (0.3â€“0.4)
-BatchNormalization
-SE channel recalibration (via SE Blocks)

## ï¿½ğŸš€ Features

- **Real-time Emotion Detection**: Upload audio files and get instant emotion predictions
- **Multiple Audio Formats**: Supports WAV, MP3, FLAC, and M4A files (local version)
- **Visual Analysis**: Interactive MFCC feature visualization and confidence scoring
- **User-friendly Interface**: Clean, modern UI with detailed explanations
- **High Accuracy**: Deep CNN model with SE-Blocks for robust emotion recognition
- **Demo Mode**: Cloud deployment shows sample predictions without audio processing

## ğŸ¯ Supported Emotions

- Neutral
- Calm  
- Happy
- Sad
- Angry
- Fearful
- Disgust

## ğŸ› ï¸ Technology Stack

- **Frontend**: Streamlit
- **ML Framework**: TensorFlow/Keras
- **Audio Processing**: Librosa (local version)
- **Feature Extraction**: MFCC (Mel-Frequency Cepstral Coefficients)
- **Visualization**: Matplotlib, Seaborn

## ğŸ“Š Model Architecture

- Deep Convolutional Neural Network with SE-Blocks
- 60 MFCC coefficients as input features
- Processes 3-second audio segments at 22,050 Hz sample rate
- Custom focal loss for handling class imbalance

## ğŸš€ Quick Start

### Local Installation

1. Clone the repository:
```bash
git clone <your-repo-url>
cd emotion_classification_on_speechdata
```

2. Install dependencies:
```bash
pip install -r requirements.txt
```

3. Run the app:
```bash
streamlit run app.py
```

### Streamlit Cloud Deployment

This app is ready for deployment on Streamlit Cloud. Simply:

1. Push your code to GitHub
2. Connect your GitHub repository to Streamlit Cloud
3. Deploy with one click!

## ğŸ“ Project Structure

```
emotion_classification_on_speechdata/
â”œâ”€â”€ app.py                 # Main Streamlit application
â”œâ”€â”€ model/                 # Pre-trained model files
â”‚   â”œâ”€â”€ emotion_model (2).h5
â”‚   â”œâ”€â”€ label_encoder (3).pkl
â”‚   â””â”€â”€ scaler (2).pkl
â”œâ”€â”€ requirements.txt       # Python dependencies
â”œâ”€â”€ packages.txt          # System packages for Streamlit Cloud
â”œâ”€â”€ runtime.txt           # Python version specification
â””â”€â”€ .streamlit/
    â””â”€â”€ config.toml       # Streamlit configuration
```

## ğŸµ Usage

1. **Upload Audio**: Choose an audio file in supported formats
2. **View Analysis**: See file information and audio player
3. **Get Predictions**: View detected emotion with confidence scores
4. **Explore Features**: Examine MFCC visualizations and audio characteristics

## ğŸ“‹ Requirements

See `requirements.txt` for detailed Python package requirements.

## ğŸ”§ Configuration

The app includes optimized configuration for Streamlit Cloud deployment:
- Maximum upload size: 200MB
- Custom theme with professional styling
- Efficient caching for model loading

## ğŸ¤ Contributing

Feel free to submit issues and enhancement requests!

## ğŸ“„ License

This project is open source and available under the MIT License.
